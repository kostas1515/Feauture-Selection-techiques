{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Techniques and Manipulation\n",
    "\n",
    "This tutorial presents  techniques and manpulation ways for features in text categorization problems. It explains how to work with text data, transform them into numbers and built custom feature selection methods, or just find significant properties.\n",
    "\n",
    "#### Requirements\n",
    "The level of this tutorial is intermediate. It requires basic understanding of numpy, scipy, sparse matrices and sklearn libraries.\n",
    "\n",
    "#### Motivation\n",
    "Have you ever wandered how sklearn's functions work? Did you ever find their use insufficient or did you ever wanted to modify some modules regarding feature selection? I hope this tutorial will answer some of your question and help you start hacking your way through data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose you have the following corpus**\n",
    "\n",
    "```\n",
    "corpus = [\n",
    "    'This is the first document this.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "    'This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\"\n",
    "]\n",
    "```\n",
    "* How would you count how many times the word *document* occurs in the corpus?\n",
    "* How would you delete it from the whole corpus?\n",
    "* How would you identify in which sentences this word appear?\n",
    "\n",
    "**Let's try this out in the most straight-forward way:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting words\n",
    "corpus = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document',\n",
    "    'This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\"\n",
    "]\n",
    "\n",
    "result=0\n",
    "for text in corpus:\n",
    "    for word in text.split():\n",
    "        if word==\"document\":\n",
    "            result=result+1\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting words\n",
    "corpus = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document',\n",
    "    'This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\"\n",
    "]\n",
    "\n",
    "k=0\n",
    "for text in corpus:\n",
    "    temp_list = text.split()\n",
    "    for word in temp_list:\n",
    "        if word==\"document\":\n",
    "            temp_list.remove(word)\n",
    "    corpus[k] = ' '.join(temp_list)\n",
    "    k=k+1\n",
    "            \n",
    "print(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying words\n",
    "corpus = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document',\n",
    "    'This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\"\n",
    "]\n",
    "\n",
    "\n",
    "flag=0\n",
    "identification_list=[]\n",
    "for text in corpus:\n",
    "    temp_list = text.split()\n",
    "    for word in temp_list:\n",
    "        if word==\"document\":\n",
    "            flag=1\n",
    "    identification_list.append(flag)\n",
    "    flag=0\n",
    "\n",
    "            \n",
    "print(identification_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the way you think about text\n",
    "Instead of scanning the document, try converting it into a **matrix represenation** and perform all the actions **column-wise** and **row-wise**\n",
    "We can use **CountVectorizer** from sklearn to achieve that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'and', 'beleive', 'book', 'do', 'document', 'everything', 'example', 'favourite', 'feature', 'first', 'harry', 'is', 'kittens', 'love', 'my', 'not', 'of', 'one', 'potter', 'read', 'second', 'selection', 'the', 'third', 'this', 'you']\n",
      "[[0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document',\n",
    "    'This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\"\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(X.toarray())  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "# count every word how many times it appears in a corpus\n",
    "k=0\n",
    "amount_of_features=X.shape[1]\n",
    "score=[]\n",
    "while(k<amount_of_features):\n",
    "            arr=X[:,k]\n",
    "            arr=arr.toarray()\n",
    "            score.append(np.sum(arr))\n",
    "            k=k+1\n",
    "print(score)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Masks\n",
    "**Masks** are matrices that act uppon other sparce matrices and change them according to a specific way. They can change their elements according to some pattern.\n",
    "For example if we want to drop the column containing the word *document*, we have to make a mask that act uppon that column. \n",
    "The column containing the word is number **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "pattern=[]\n",
    "for feature in vectorizer.get_feature_names():\n",
    "    if (feature== \"document\"):\n",
    "        pattern.append(False)\n",
    "    else:\n",
    "        pattern.append(True)\n",
    "print(pattern)\n",
    "mask=np.array(pattern, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old X\n",
      "[[0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1]]\n",
      "\n",
      " new X\n",
      "[[0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#drop the row containing the word document\n",
    "print('old X')\n",
    "print(X.A)\n",
    "print(\"\\n new X\")\n",
    "X_new=X[:,mask]\n",
    "print(X_new.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Non relevant features\n",
    "Let's say we have the same corpus with relevant and non-relevant documents.\n",
    "\n",
    "How would you remove all non relevant features from corpus?\n",
    "\n",
    "|             document                  | relevance|\n",
    "|---------------------------------------|----------|\n",
    "|This is the first document this        |    Yes   |\n",
    "|This document is the second document   |    Yes   |\n",
    "|And this is the third one              |     No   |\n",
    "|Is this the first document             |    Yes   |\n",
    "|This is an example of feature selection|    Yes   |\n",
    "|I love kittens                         |     No   |\n",
    "|My favourite book is Harry Potter      |     No   |\n",
    "|Do not beleive everything you read     |    Yes   |\n",
    "\n",
    "#### You can use masks to do that!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old X\n",
      "[[0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1]]\n",
      "\n",
      " new X\n",
      "[[0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document',\n",
    "    'This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\"\n",
    "]\n",
    "relevance=[1, 1, 0, 1, 1, 0, 0, 1]\n",
    "mask= np.array(relevance, dtype=bool)\n",
    "print(\"old X\")\n",
    "print(X.A)\n",
    "print(\"\\n new X\")\n",
    "new_X=X[mask]\n",
    "print(new_X.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice that new X is not exactly correct because it contains empy rows.\n",
    "#### These rows correspond to features not being used, and they need to be removed.\n",
    "#### To remove the we construct again the appropriate mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False  True  True  True  True False  True  True False\n",
      "  True False False False  True  True False False  True  True  True  True\n",
      " False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# make the mask\n",
    "mask =  new_X.getnnz(0)>0\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old new_X\n",
      "[[0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1]]\n",
      "\n",
      " new new_X\n",
      "[[0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 2 0 0 0 0 1 0 0 0 1 0 1 1 0]\n",
      " [0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0]\n",
      " [1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#drop the column\n",
    "print(\"old new_X\")\n",
    "print(new_X.A)\n",
    "new_X=new_X[:,mask]\n",
    "print(\"\\n new new_X\")\n",
    "print(new_X.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant document frequency\n",
    "RDF is a filtering feature selection method that assigns each feature with a score depending on how many times that feature occur in relevant documents. After that it selects the best relevant features and produce a better train set.\n",
    "\n",
    "Using the same corpus we will selekt the top 5 features and reform both train and test set.\n",
    "\n",
    "|             document                  | relevance| |\n",
    "|---------------------------------------|----------|---|\n",
    "|This is the first document this        |    Yes   |train_set|\n",
    "|This document is the second document   |    Yes   |train_set|\n",
    "|And this is the third one              |     No   |train_set|\n",
    "|Is this the first document             |    Yes   |train_set|\n",
    "|This is an example of feature selection|    Yes   |test_set |\n",
    "|I love kittens                         |     No   |test_set |\n",
    "|My favourite book is Harry Potter      |     No   |test_set |\n",
    "|Do not beleive everything you read     |    Yes   |test_set |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "x_train = [\n",
    "    'This is the first document',\n",
    "    'This document is the second document',\n",
    "    'And this is the third one',\n",
    "    'Is this the first document' ]\n",
    "y_train =[1,1,0,1]\n",
    "\n",
    "x_test = ['This is an example of feature selection',\n",
    "    'I love kittens',\n",
    "    'My favourite book is Harry Potter',\n",
    "    \"Do not beleive everything you read\" ]\n",
    "y_test=[1,0,0,1]\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(x_train)\n",
    "X_test = vectorizer.transform(x_test)\n",
    "print(X_train.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_rel is:\n",
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]\n",
      " [1 1 1 0 1 1]]\n",
      "\n",
      "the new_x_train without non-relevant features is\n",
      "\n",
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]\n",
      " [0 0 1 0 1 1]\n",
      " [1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "mask1 = np.array(y_train, dtype=bool) # this is an only rel_doc mask \n",
    "\n",
    "x_rel_train= X_train[mask1] # this is a matrix containing only rel_docs in countvectorizer fashion\n",
    "\n",
    "mask = x_rel_train.getnnz(0)>0 # this is the mask, 1-d array containing only rel_features, it has the length of all features and ones in rel - zeros in nonrel\n",
    "\n",
    "x_rel_train= x_rel_train[:,mask] # this is the matrix with [rel_docs x rel_features]\n",
    "print(\"x_rel is:\")\n",
    "print(x_rel_train.A)\n",
    "\n",
    "new_X_test1 = X_test[:,mask]\n",
    "new_X_train1= X_train[:,mask]\n",
    "\n",
    "print(\"\\nthe new_x_train without non-relevant features is\\n\" )\n",
    "print(new_X_train1.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "score=[]\n",
    "amount_of_features=x_rel_train.shape[1]\n",
    "while(k<amount_of_features):\n",
    "    arr=x_rel_train[:,k]\n",
    "    arr=arr.toarray()\n",
    "    arr=np.where(arr > 0, 1, 0) # because we need just one, not the total amount of particular feature in that documnt so if there is above zero make it 1 (like binary countvectorizer)\n",
    "    score.append(np.sum(arr))\n",
    "    k=k+1\n",
    "\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True]\n",
      "\n",
      "\n",
      "old X_train\n",
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]\n",
      " [0 0 1 0 1 1]\n",
      " [1 1 1 0 1 1]]\n",
      "\n",
      " new X_train\n",
      "[[1 1 1 1 1]\n",
      " [2 0 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "\n",
      " new_X_test1\n",
      "[[0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n",
      "new_X_test2\n",
      "[[0 0 1 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# creating the mask\n",
    "topk=5\n",
    "mask = np.zeros(len(score), dtype=bool) ######## this code is from sklearns selectkbest it makes a mask with ones in selected features and zeros to not selected\n",
    "mask[np.argsort(score, kind=\"mergesort\")[-topk:]] = True\n",
    "print(mask)\n",
    "print(\"\\n\")\n",
    "new_X_train2= new_X_train1[:,mask]\n",
    "new_X_test2 = new_X_test1[:,mask]\n",
    "\n",
    "print(\"old X_train\")\n",
    "print(new_X_train1.A)\n",
    "print(\"\\n new X_train\")\n",
    "print(new_X_train2.A)\n",
    "\n",
    "print(\"\\n new_X_test1\")\n",
    "print(new_X_test1.A)\n",
    "print(\"\\nnew_X_test2\")\n",
    "print(new_X_test2.A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "* We built a custom feature selection method, relevant document frequency. \n",
    "* We understood how to transform train set and test set accordingly \n",
    "* We understood how selectkbest works from sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
